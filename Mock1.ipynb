{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('img/1649089282389.jpg')\n",
    "\n",
    "scale_percent = 100 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "gray = cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "rho = 1\n",
    "theta = np.pi / 180\n",
    "threshold = 15\n",
    "min_line_length = 50\n",
    "max_line_gap = 50\n",
    "\n",
    "line_image = np.copy(resized) * 0\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "\n",
    "for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "        \n",
    "lines_edges = cv2.addWeighted(resized, 0.8, line_image, 1, 0)\n",
    "cv2.imwrite('img/houghlines5.jpg', lines_edges)\n",
    "# cv2.imwrite('img/gray.jpg',gray)\n",
    "# cv2.imwrite('img/edges.jpg', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('img/1649089282389.jpg')\n",
    "\n",
    "scale_percent = 20 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "img_blur = cv2.blur(resized, (3, 3))\n",
    "img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(\n",
    "    img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 4\n",
    ")\n",
    "\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# for c in contours:\n",
    "#     peri = cv2.arcLength(c, True)\n",
    "#     approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "\n",
    "# cv2.drawContours(resized, contours, -1, 255, 3)\n",
    "c = max(contours, key=cv2.contourArea)\n",
    "# x, y, w, h = cv2.boundingRect(c)\n",
    "# cv2.rectangle(resized,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "mask = np.zeros((img_gray.shape), np.uint8)\n",
    "\n",
    "# for c in contours:\n",
    "hull = cv2.convexHull(c)\n",
    "cv2.drawContours(mask, [hull], 0, 255, -1)\n",
    "cv2.drawContours(mask, [hull], 0, 0, 2)\n",
    "\n",
    "cropImg = np.zeros_like(gray)\n",
    "cropImg[mask == 255] = gray[mask == 255]\n",
    "\n",
    "# thresh = cv2.adaptiveThreshold(\n",
    "#     cropImg, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 4\n",
    "# )\n",
    "edges = cv2.Canny(cropImg,50,150,apertureSize = 3)\n",
    "\n",
    "rho = 1\n",
    "theta = np.pi / 180\n",
    "threshold = 15\n",
    "min_line_length = 50\n",
    "max_line_gap = 35\n",
    "\n",
    "line_image = np.copy(cropImg) * 0\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "\n",
    "for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "        \n",
    "lines_edges = cv2.addWeighted(cropImg, 0.8, line_image, 1, 0)\n",
    "\n",
    "cv2.imshow('treshold', lines_edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DRAGAN~1\\AppData\\Local\\Temp/ipykernel_19844/2821586378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img/1649093114788.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m \u001b[1;31m# percent of original size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('img/1649093114788.jpg')\n",
    "\n",
    "scale_percent = 40 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "img_blur = cv2.blur(resized, (3, 3))\n",
    "img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(\n",
    "    img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 4\n",
    ")\n",
    "\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# for c in contours:\n",
    "#     peri = cv2.arcLength(c, True)\n",
    "#     approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "\n",
    "# cv2.drawContours(resized, contours, -1, 255, 3)\n",
    "c = max(contours, key=cv2.contourArea)\n",
    "# x, y, w, h = cv2.boundingRect(c)\n",
    "# cv2.rectangle(resized,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "\n",
    "mask = np.zeros((img_gray.shape), np.uint8)\n",
    "\n",
    "# for c in contours:\n",
    "hull = cv2.convexHull(c)\n",
    "cv2.drawContours(mask, [hull], 0, 255, -1)\n",
    "cv2.drawContours(mask, [hull], 0, 0, 2)\n",
    "\n",
    "cropImg = np.zeros_like(img_gray)\n",
    "cropImg[mask == 255] = img_gray[mask == 255]\n",
    "\n",
    "# gray= cv2.cvtColor(cropImg,cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.SIFT_create()\n",
    "kp = sift.detect(cropImg,None)\n",
    "img=cv2.drawKeypoints(cropImg,kp, cropImg)\n",
    "cv2.imwrite('img/sift_keypoints.jpg',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def getBoard(imgPath):\n",
    "    img = cv2.imread(imgPath)\n",
    "    scale_percent = 30 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    \n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    img_blur = cv2.GaussianBlur(resized, (5, 5), cv2.BORDER_DEFAULT)\n",
    "    img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 4\n",
    "    )\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros((img_gray.shape), np.uint8)\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(mask, [hull], 0, 255, -1)\n",
    "    cv2.drawContours(mask, [hull], 0, 0, 2)\n",
    "\n",
    "    cropImg = np.zeros_like(resized)\n",
    "    cropImg[mask == 255] = resized[mask == 255]\n",
    "\n",
    "    # dst = cv2.cornerHarris(mask,4,5,0.04)\n",
    "    # #result is dilated for marking the corners, not important\n",
    "    # dst = cv2.dilate(dst,None)\n",
    "    # dst[dst>0.6*dst.max()]=255\n",
    "\n",
    "\n",
    "    # Threshold for an optimal value, it may vary depending on the image.\n",
    "    # print(len(cropImg[dst==255]))\n",
    "    # cropImg[dst==255] = [255, 0, 0]\n",
    "\n",
    "\n",
    "    cv2.imshow('img/sift_keypoints.jpg',mask)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "getBoard('img/1649270859998.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of countours  169\n",
      "Old Screen Dimentions filtered [6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 5, 5, 7]\n",
      "Screen Dimentions filtered [823, 823]\n",
      "Found bill rectagle at  [[152  52]\n",
      " [154 828]\n",
      " [972 796]\n",
      " [960  75]]\n",
      "[[152.  52.]\n",
      " [960.  75.]\n",
      " [972. 796.]\n",
      " [154. 828.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 98,  98,  98],\n",
       "        [ 94,  94,  94],\n",
       "        [ 91,  91,  91],\n",
       "        ...,\n",
       "        [ 97,  97,  97],\n",
       "        [102, 102, 102],\n",
       "        [100, 100, 100]],\n",
       "\n",
       "       [[ 94,  94,  94],\n",
       "        [ 94,  94,  94],\n",
       "        [ 95,  95,  95],\n",
       "        ...,\n",
       "        [103, 103, 103],\n",
       "        [103, 103, 103],\n",
       "        [107, 107, 107]],\n",
       "\n",
       "       [[ 93,  93,  93],\n",
       "        [ 98,  98,  98],\n",
       "        [ 98,  98,  98],\n",
       "        ...,\n",
       "        [103, 103, 103],\n",
       "        [102, 102, 102],\n",
       "        [106, 106, 106]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[106, 106, 106],\n",
       "        [106, 106, 106],\n",
       "        [109, 109, 109],\n",
       "        ...,\n",
       "        [104, 104, 104],\n",
       "        [105, 105, 105],\n",
       "        [102, 102, 102]],\n",
       "\n",
       "       [[102, 102, 102],\n",
       "        [102, 102, 102],\n",
       "        [105, 105, 105],\n",
       "        ...,\n",
       "        [105, 105, 105],\n",
       "        [106, 106, 106],\n",
       "        [103, 103, 103]],\n",
       "\n",
       "       [[ 91,  91,  91],\n",
       "        [ 90,  90,  90],\n",
       "        [ 90,  90,  90],\n",
       "        ...,\n",
       "        [106, 106, 106],\n",
       "        [106, 106, 106],\n",
       "        [106, 106, 106]]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "#function to order points to proper rectangle\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "#function to transform image to four points\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "\n",
    "    # # multiply the rectangle by the original ratio\n",
    "    # rect *= ratio\n",
    "\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped\n",
    "\n",
    "\n",
    "#function to find two largest countours which ones are may be\n",
    "#  full image and our rectangle edged object\n",
    "def findLargestCountours(cntList, cntWidths):\n",
    "    newCntList = []\n",
    "    newCntWidths = []\n",
    "\n",
    "    #finding 1st largest rectangle\n",
    "    first_largest_cnt_pos = cntWidths.index(max(cntWidths))\n",
    "\n",
    "    # adding it in new\n",
    "    newCntList.append(cntList[first_largest_cnt_pos])\n",
    "    newCntWidths.append(cntWidths[first_largest_cnt_pos])\n",
    "\n",
    "    #removing it from old\n",
    "    cntList.pop(first_largest_cnt_pos)\n",
    "    cntWidths.pop(first_largest_cnt_pos)\n",
    "\n",
    "    #finding second largest rectangle\n",
    "    seccond_largest_cnt_pos = cntWidths.index(max(cntWidths))\n",
    "\n",
    "    # adding it in new\n",
    "    newCntList.append(cntList[seccond_largest_cnt_pos])\n",
    "    newCntWidths.append(cntWidths[seccond_largest_cnt_pos])\n",
    "\n",
    "    #removing it from old\n",
    "    cntList.pop(seccond_largest_cnt_pos)\n",
    "    cntWidths.pop(seccond_largest_cnt_pos)\n",
    "\n",
    "    print('Old Screen Dimentions filtered', cntWidths)\n",
    "    print('Screen Dimentions filtered', newCntWidths)\n",
    "    return newCntList, newCntWidths\n",
    "\n",
    "\n",
    "#driver function which identifieng 4 corners and doing four point transformation\n",
    "def convert_object(image, screen_size = None, isDebug = False):\n",
    "\n",
    "    # image = imutils.resize(image, height=300)\n",
    "    # ratio = image.shape[0] / 300.0\n",
    "\n",
    "\n",
    "    # convert the image to grayscale, blur it, and find edges\n",
    "    # in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)  # 11  //TODO 11 FRO OFFLINE MAY NEED TO TUNE TO 5 FOR ONLINE\n",
    "\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    edged = cv2.Canny(gray, 30, 400)\n",
    "\n",
    "    if isDebug  : cv2.imwrite('edged.jpg', edged)\n",
    "    # find contours in the edged image, keep only the largest\n",
    "    # ones, and initialize our screen contour\n",
    "\n",
    "    countours, hierarcy = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if isDebug : print('length of countours ', len(countours))\n",
    "\n",
    "    imageCopy = image.copy()\n",
    "    if isDebug : cv2.imwrite('drawn_countours.jpg', cv2.drawContours(imageCopy, countours, -1, (0, 255, 0), 1))\n",
    "    \n",
    "\n",
    "\n",
    "    # approximate the contour\n",
    "    cnts = sorted(countours, key=cv2.contourArea, reverse=True)\n",
    "    screenCntList = []\n",
    "    scrWidths = []\n",
    "    for cnt in cnts:\n",
    "        peri = cv2.arcLength(cnt, True)  # cnts[1] always rectangle O.o\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "        screenCnt = approx\n",
    "        # print(len(approx))\n",
    "\n",
    "        if (len(screenCnt) == 4):\n",
    "\n",
    "            (X, Y, W, H) = cv2.boundingRect(cnt)\n",
    "            # print('X Y W H', (X, Y, W, H))\n",
    "            screenCntList.append(screenCnt)\n",
    "            scrWidths.append(W)\n",
    "\n",
    "        # else:\n",
    "        #     print(\"4 points not found\")\n",
    "\n",
    "    # print('Screens found :', len(screenCntList))\n",
    "    # print('Screen Dimentions', scrWidths)\n",
    "\n",
    "    screenCntList, scrWidths = findLargestCountours(screenCntList, scrWidths)\n",
    "\n",
    "    if not len(screenCntList) >=2: #there is no rectangle found\n",
    "        return None\n",
    "    elif scrWidths[0] != scrWidths[1]: #mismatch in rect\n",
    "        return None\n",
    "\n",
    "    if isDebug : cv2.imwrite(\"Screen.jpg\", cv2.drawContours(image.copy(), [screenCntList[0]], -1, (0, 255, 0), 3))\n",
    "\n",
    "    # now that we have our screen contour, we need to determine\n",
    "    # the top-left, top-right, bottom-right, and bottom-left\n",
    "    # points so that we can later warp the image -- we'll start\n",
    "    # by reshaping our contour to be our finals and initializing\n",
    "    # our output rectangle in top-left, top-right, bottom-right,\n",
    "    # and bottom-left order\n",
    "    pts = screenCntList[0].reshape(4, 2)\n",
    "    print('Found bill rectagle at ', pts)\n",
    "    rect = order_points(pts)\n",
    "    print(rect)\n",
    "\n",
    "    # apply the four point tranform to obtain a \"birds eye view\" of\n",
    "    # the image\n",
    "    warped = four_point_transform(image, pts)\n",
    "\n",
    "    # convert the warped image to grayscale and then adjust\n",
    "    # the intensity of the pixels to have minimum and maximum\n",
    "    # values of 0 and 255, respectively\n",
    "    warp = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    # warp = exposure.rescale_intensity(warp, out_range=(0, 255))\n",
    "    warp = cv2.normalize(warp, None, alpha=0,beta=200, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    # show the original and warped images\n",
    "    cv2.imshow(\"Original\", image)\n",
    "    cv2.imshow(\"warp\", warp)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    if(screen_size != None):\n",
    "        return cv2.cvtColor(cv2.resize(warp, screen_size), cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        return cv2.cvtColor(warp, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "img = cv2.imread('img/1649093114788.jpg')\n",
    "scale_percent = 30 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "convert_object(resized, isDebug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
